{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import scanpy.api as sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"data/\"\n",
    "data_file = \"matrix.mtx\"\n",
    "var_names_file = \"genes.tsv\"\n",
    "obs_names_file = \"barcodes.tsv\"\n",
    "output_h5ad_file = \"68kPBMCs.h5ad\"\n",
    "\n",
    "data_path = os.path.join(dataset_dir,data_file)\n",
    "var_names_path = os.path.join(dataset_dir,var_names_file)\n",
    "obs_names_path = os.path.join(dataset_dir,obs_names_file)\n",
    "output_h5ad_path = os.path.join(dataset_dir,output_h5ad_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(var_names_path, \"r\") as var_file:\n",
    "    var_read = csv.reader(var_file, delimiter='\\t')\n",
    "    var_names = []\n",
    "    for row in var_read:\n",
    "        var_names.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(obs_names_path, \"r\") as obs_file:\n",
    "    obs_read = csv.reader(obs_file, delimiter='\\t')\n",
    "    obs_names = []\n",
    "    for row in obs_read:\n",
    "        obs_names.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "andata = sc.read(data_path) \n",
    "andata = andata.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    }
   ],
   "source": [
    "andata.var_names = var_names\n",
    "andata.var_names_make_unique()\n",
    "andata.obs_names = obs_names\n",
    "andata.obs_names_make_unique()\n",
    "\n",
    "andata.write(filename=output_h5ad_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering of the raw data is done with minimum 10 genes per cell.\n",
      "Filtering of the raw data is done with minimum 3 cells per gene.\n",
      "Cells number is 68579 , with 17789 genes per cell.\n"
     ]
    }
   ],
   "source": [
    "# filtering \n",
    "\n",
    "min_cells = 3,\n",
    "min_genes = 10\n",
    "\n",
    "sc_raw = andata\n",
    "\n",
    "sc.pp.filter_cells(sc_raw, min_genes=min_genes, copy=False)\n",
    "print(\"Filtering of the raw data is done with minimum \"\n",
    "      \"%d genes per cell.\" % min_genes)\n",
    "\n",
    "sc.pp.filter_genes(sc_raw, min_cells=min_cells, copy=False)\n",
    "print(\"Filtering of the raw data is done with minimum\"\n",
    "      \" %d cells per gene.\" % min_cells)\n",
    "\n",
    "cells_count = sc_raw.shape[0]\n",
    "genes_count = sc_raw.shape[1]\n",
    "\n",
    "print(\"Cells number is %d , with %d genes per cell.\"\n",
    "      % (cells_count, genes_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling of the data is done using normalize_per_cell_LS with 20000\n"
     ]
    }
   ],
   "source": [
    "# scaling\n",
    "scale = \"normalize_per_cell_LS_20000\"\n",
    "\n",
    "if \"normalize_per_cell_LS_\" in str(scale):\n",
    "\n",
    "    lib_size = int(scale.split('_')[-1])\n",
    "    sc.pp.normalize_per_cell(sc_raw,\n",
    "                             counts_per_cell_after=lib_size)\n",
    "    scale = {\"scaling\": 'normalize_per_cell_LS',\n",
    "                  \"scale_value\": lib_size}\n",
    "\n",
    "else:\n",
    "\n",
    "    warnings.warn(\"The scaling of the data is unknown, library size \"\n",
    "                  \"library size normalization with 20k will be applied\")\n",
    "\n",
    "    lib_size = int(sscale.split('_')[-1])\n",
    "    sc.pp.normalize_per_cell(sc_raw,\n",
    "                             counts_per_cell_after=lib_size)\n",
    "    self.scale = {\"scaling\": 'normalize_per_cell_LS',\n",
    "                  \"scale_value\": lib_size}\n",
    "\n",
    "print(\"Scaling of the data is done using \" + scale[\"scaling\"]\n",
    "      + \" with \" + str(scale[\"scale_value\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_h5ad_processed_file = \"68kPBMCs_processed.h5ad\"\n",
    "output_h5ad_processed_path = os.path.join(dataset_dir, output_h5ad_processed_file)\n",
    "sc_raw.write(output_h5ad_processed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.        0.        0.       ...  0.       16.447369  0.      ]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "sct = collections.namedtuple('sc', ('barcode', 'count_no', 'genes_no'))\n",
    "exp_share = 0.2\n",
    "n_exp_data = int(exp_share * sc_raw.shape[0])\n",
    "sc_raw_exp = sc_raw[:n_exp_data]\n",
    "\n",
    "train_data = np.zeros((sc_raw_exp.shape[0], sc_raw_exp.shape[1]))\n",
    "\n",
    "def process_line(line):\n",
    "    scmd = sct(barcode=line.obs_names[0],\n",
    "               count_no=int(np.sum(line.X)),\n",
    "               genes_no=line.obs['n_genes'][0]\n",
    "              )\n",
    "    return line.X, scmd\n",
    "\n",
    "\n",
    "for i, line in enumerate(sc_raw_exp):\n",
    "    sc_genes, d = process_line(line)\n",
    "    print(sc_genes)\n",
    "    train_data[i] = sc_genes\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68579, 17789)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13715, 17789)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17789,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(sc_raw_exp):\n",
    "    sc_genes, d = process_line(line)\n",
    "    print(sc_genes.shape)\n",
    "    print(type(sc_genes))\n",
    "    train_data[i] = sc_genes\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "        16.44736862,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scganpytorch] *",
   "language": "python",
   "name": "conda-env-scganpytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
